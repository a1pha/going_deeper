{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import array\n",
    "\n",
    "def read_and_process_images(list_of_images):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        X.append(cv2.resize(cv2.imread(\"class5_data/\" + str(image), cv2.IMREAD_GRAYSCALE), (50,50), interpolation = cv2.INTER_CUBIC))\n",
    "        \n",
    "        if 'apple' in str(image):\n",
    "            y.append(0)\n",
    "        \n",
    "        if 'banana' in str(image):\n",
    "            y.append(1)\n",
    "        \n",
    "        if 'water' in str(image):\n",
    "            y.append(2)\n",
    "        \n",
    "        if 'potato' in str(image):\n",
    "            y.append(3)\n",
    "        \n",
    "        if 'instant' in str(image):\n",
    "            y.append(4)\n",
    "    return array(X),array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dirListing = os.listdir(\"class5_data\")\n",
    "for filename in dirListing:\n",
    "    file_names.append(str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_and_process_images(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1419,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (1200, 50, 50, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 50, 50, 50)        1300      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 25, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 25, 25, 100)       125100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 13, 13, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 13, 13, 200)       500200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 200)         1000200   \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 7, 200)         1000200   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 4, 4, 400)         2000400   \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 4, 4, 400)         4000400   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 400)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 2, 2, 200)         2000200   \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 2, 2, 200)         1000200   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 2005      \n",
      "=================================================================\n",
      "Total params: 11,871,005\n",
      "Trainable params: 11,871,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download and visualize the data: see all here https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "start = 0 \n",
    "middle = 1200\n",
    "end = 1419\n",
    "X_train = X[0:middle].reshape(X[0:middle].shape[0], 50, 50,1)\n",
    "y_train = tf.keras.utils.to_categorical(y[0:middle], 5)\n",
    "\n",
    "\n",
    "X_val = X[middle:end].reshape(X[middle:end].shape[0], 50, 50, 1)\n",
    "y_val = tf.keras.utils.to_categorical(y[middle:end], 5)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(50,50), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[5].reshape(50,50), cmap=plt.cm.Greys);\n",
    "\n",
    "\n",
    "# Build your DNN, an example model is given for you.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, (5,5), padding='same', activation='relu', input_shape=(50, 50,1)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(200, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(200, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(200, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(400, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(400, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(200, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(200, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(400, activation='relu'),\n",
    "    tf.keras.layers.Dense(400, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 219 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 14s 12ms/sample - loss: 1.0326 - acc: 0.5708 - val_loss: 0.5994 - val_acc: 0.7717\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.4957 - acc: 0.8092 - val_loss: 0.2850 - val_acc: 0.8904\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.2719 - acc: 0.9033 - val_loss: 0.3870 - val_acc: 0.8356\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 13s 11ms/sample - loss: 0.1717 - acc: 0.9392 - val_loss: 0.0882 - val_acc: 0.9726\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.1956 - acc: 0.9408 - val_loss: 0.2471 - val_acc: 0.9406\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.1024 - acc: 0.9642 - val_loss: 0.0355 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.0370 - acc: 0.9883 - val_loss: 0.6150 - val_acc: 0.8676\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 13s 11ms/sample - loss: 0.1585 - acc: 0.9550 - val_loss: 0.0758 - val_acc: 0.9726\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.0165 - acc: 0.9958 - val_loss: 0.0194 - val_acc: 0.9954\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 14s 11ms/sample - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0161 - val_acc: 0.9954\n"
     ]
    }
   ],
   "source": [
    "hist1 = model.fit(X_train, y_train,\n",
    "          batch_size=25,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val.reshape(X_val.shape[0], 50, 50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_val.argmax(axis=1), predictions.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0,  0,  0],\n",
       "       [ 0, 23,  0,  0,  0],\n",
       "       [ 0,  0, 61,  0,  0],\n",
       "       [ 0,  0,  0, 39,  1],\n",
       "       [ 0,  0,  0,  0, 66]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
